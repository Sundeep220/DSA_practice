Below is a **clean, interview-ready + notes-style deep dive** into **Disjoint Set (DSU / Unionâ€“Find)** with **Union by Rank**, **Union by Size**, and **Path Compression**, written so you can **directly add this to your DSA notes**.

---

![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2AecQEL6cJA6I-RflbxbociA.png)

![Image](https://cp-algorithms.com/data_structures/DSU_path_compression.png)

![Image](https://static.takeuforward.org/wp/uploads/2022/12/Screenshot-2022-12-14-184818.png)

![Image](https://tutorialhorizon.com/static/media/algorithms/2018/04/Union-by-Rank.png)

# Disjoint Set (Unionâ€“Find) â€“ Complete Notes (G-46)

## 1. Why do we need Disjoint Set?

### Problem

Given an **undirected graph**, answer queries like:

> Are node **u** and node **v** in the **same connected component**?

### Brute Force

* Use **DFS / BFS**
* Time per query: **O(N + E)**
* âŒ Too slow if graph keeps changing

### Disjoint Set (DSU)

* Handles **dynamic graphs** (edges added over time)
* Answers:

    * `find(u)` â†’ which component u belongs to
    * `union(u, v)` â†’ connect two components
* Time per operation: **Almost O(1)** âœ…

---

## 2. Dynamic Graph Intuition

Edges added one by one:

```
{1â€“2}, {2â€“3}, {4â€“5}, {6â€“7}, {5â€“6}, {3â€“7}
```

* After 4 edges â†’ `{1,2,3}` and `{4,5}` and `{6,7}`
* After all edges â†’ **all nodes connected**

DSU can answer connectivity **after every edge addition** efficiently.

---

## 3. Core Concepts

### Parent

* `parent[x]` â†’ immediate parent of node `x`

### Ultimate Parent (Root)

* The **topmost parent** of a node
* Defines the component

### Rank

* Approximate **height of the tree**
* Used only for **balancing**

### Size

* Number of nodes in a component
* Used as an alternative to rank

---

## 4. Why Ultimate Parent Matters?

Two nodes are in the same component **iff**:

```
find(u) == find(v)
```

Immediate parents may differ,
but **ultimate parents decide connectivity**.

---

## 5. findPar() + Path Compression

### Basic find (slow)

```
u â†’ parent â†’ parent â†’ parent â†’ root
```

### Path Compression (fast)

* While finding root, directly attach nodes to root
* Flattens the tree

### Algorithm

1. If `node == parent[node]`, return node
2. Else:

    * `parent[node] = find(parent[node])`
    * Return parent[node]

### Effect

* Tree height becomes very small
* Future finds become **O(1)**

---

## 6. Union by Rank

### Idea

Always attach **smaller height tree** under **larger height tree**

### Why?

* Keeps tree **shallow**
* Faster `find()` operations

### Rules

1. Find roots `pu`, `pv`
2. If ranks differ â†’ attach smaller rank under larger rank
3. If equal â†’ attach any one & **increase rank by 1**

---

## 7. Java Code â€“ Union by Rank + Path Compression

```java
class DisjointSet {
    int[] parent;
    int[] rank;

    DisjointSet(int n) {
        parent = new int[n + 1];
        rank = new int[n + 1];

        for (int i = 0; i <= n; i++) {
            parent[i] = i;
            rank[i] = 0;
        }
    }

    // Path Compression
    int findUPar(int node) {
        if (node == parent[node])
            return node;

        parent[node] = findUPar(parent[node]);
        return parent[node];
    }

    // Union by Rank
    void unionByRank(int u, int v) {
        int pu = findUPar(u);
        int pv = findUPar(v);

        if (pu == pv) return;

        if (rank[pu] < rank[pv]) {
            parent[pu] = pv;
        } else if (rank[pv] < rank[pu]) {
            parent[pv] = pu;
        } else {
            parent[pv] = pu;
            rank[pu]++;
        }
    }
}
```

---

## 8. Why Smaller Rank â†’ Larger Rank?

If we do the opposite:

* Tree height increases
* More traversal during `find`
* Path compression cost increases

Correct approach:

* Attach **shorter tree under taller**
* Keeps depth minimal

---

## 9. Rank Gets Distorted â—

After path compression:

* Actual height changes
* `rank[]` no longer reflects real depth

â¡ï¸ Hence **Union by Size** is often preferred.

---

## 10. Union by Size

### Idea

Attach **smaller component** under **larger component**

### Advantages

* More intuitive
* No distortion problem
* Works perfectly with path compression

---

## 11. Union by Size Algorithm

### Initialization

```text
parent[i] = i
size[i] = 1
```

### Steps

1. Find roots `pu`, `pv`
2. Attach smaller size component under larger
3. Update size

---

## 12. Java Code â€“ Union by Size (Recommended)

```java
class DisjointSet {
    int[] parent;
    int[] size;

    DisjointSet(int n) {
        parent = new int[n + 1];
        size = new int[n + 1];

        for (int i = 0; i <= n; i++) {
            parent[i] = i;
            size[i] = 1;
        }
    }

    int findUPar(int node) {
        if (node == parent[node])
            return node;

        parent[node] = findUPar(parent[node]);
        return parent[node];
    }

    void unionBySize(int u, int v) {
        int pu = findUPar(u);
        int pv = findUPar(v);

        if (pu == pv) return;

        if (size[pu] < size[pv]) {
            parent[pu] = pv;
            size[pv] += size[pu];
        } else {
            parent[pv] = pu;
            size[pu] += size[pv];
        }
    }
}
```

---

## 13. Time Complexity (Interview Gold â­)

* `find()` with path compression: **O(Î±(N))**
* `union()`: **O(Î±(N))**
* `Î±(N)` = Inverse Ackermann (â‰¤ 4 for all practical N)

â¡ï¸ **Considered constant time**

---

## 14. When to Use Disjoint Set?

* Connected Components
* Cycle Detection (Undirected Graph)
* Kruskalâ€™s MST
* Dynamic connectivity queries
* Grid problems (islands, regions)
* Network connectivity

---

## 15. Rank vs Size â€“ Which is Better?

| Feature                      | Union by Rank | Union by Size |
| ---------------------------- | ------------- | ------------- |
| Intuition                    | Medium        | Very High     |
| Affected by path compression | Yes           | No            |
| Preferred in practice        | âŒ             | âœ…             |
| Interview safe               | âœ…             | âœ…             |

---

### ğŸ“Œ Final Recommendation

> **Use Union by Size + Path Compression** in production & interviews.

---

# Why Disjoint Set Runs in ~O(1)

## (Derivation of `O(Î±(N))` Time Complexity)

---

## 1. What are we analyzing exactly?

For **Disjoint Set (DSU)** with:

* **Union by Rank / Size**
* **Path Compression**

We want to understand the time complexity of:

* `find()`
* `union()`

ğŸ‘‰ Claim:

```
Time per operation = O(Î±(N))
```

Where **Î±(N)** is the **Inverse Ackermann function**
(â‰¤ 4 for any real-world N)

---

## 2. First, analyze WITHOUT optimizations

### Case 1: No rank, no compression

Worst case:

```
1 â†’ 2 â†’ 3 â†’ 4 â†’ ... â†’ N
```

* Height = N
* `find()` = O(N)
* `union()` = O(N)

âŒ Too slow

---

## 3. Add Union by Rank ONLY

### What union by rank guarantees

* Tree height is **logarithmic**
* Because smaller trees attach under bigger trees

### Why height â‰¤ log N?

Each time rank increases:

* Tree size at least **doubles**

Example:

```
rank 0 â†’ size â‰¥ 1
rank 1 â†’ size â‰¥ 2
rank 2 â†’ size â‰¥ 4
rank 3 â†’ size â‰¥ 8
...
```

So:

```
max rank â‰¤ logâ‚‚N
```

### Complexity now

* `find()` = O(log N)
* `union()` = O(log N)

âœ… Better, but still not constant

---

## 4. Add Path Compression ONLY

### What path compression does

Before:

```
7 â†’ 6 â†’ 5 â†’ 4 â†’ 3 â†’ 2 â†’ 1
```

After one `find(7)`:

```
7
â”‚
â”œâ”€â”€ 6
â”œâ”€â”€ 5
â”œâ”€â”€ 4
â”œâ”€â”€ 3
â”œâ”€â”€ 2
â””â”€â”€ 1
```

All nodes point **directly to root**

### Effect

* First `find()` may be expensive
* Subsequent `find()` calls are **O(1)**

Butâ€¦
âŒ No strict upper bound alone

---

## 5. Combine BOTH (Key Insight)

When we use:

* **Union by Rank** â†’ keeps trees shallow
* **Path Compression** â†’ flattens trees aggressively

Something magical happens:

> The tree becomes *almost flat*, permanently.

This combination is what leads to **Î±(N)**.

---

## 6. Where does Î±(N) come from?

### Step 1: Ackermann Function (Grows Insanely Fast)

You do **NOT** need the full definition in interviews, but intuition matters.

Ackermann grows faster than:

* exponential
* power towers
* factorials

Even small inputs give huge values.

Example intuition:

```
A(4, 4) > number of atoms in the universe
```

---

### Step 2: Inverse Ackermann Î±(N)

Î±(N) answers:

> â€œHow many times do I need to apply Ackermann to reach N?â€

Since Ackermann grows insanely fast,
its inverse grows **insanely slowly**.

---

## 7. Practical Values of Î±(N)

This is the **most important interview takeaway**:

| N    | Î±(N) |
| ---- | ---- |
| 10   | 3    |
| 10â¶  | 4    |
| 10Â¹â¸ | 4    |
| 10â¸â° | 5    |

ğŸ‘‰ For **any conceivable input size**,
**Î±(N) â‰¤ 4**

Thatâ€™s why we treat it as **constant time**.

---

## 8. Intuition Behind the Derivation (Interview-Friendly)

Instead of math symbols, say this:

> Each nodeâ€™s parent pointer only moves **upwards**,
> and after path compression, it jumps **very close to the root**.
>
> A node can only move â€œupâ€ a very limited number of times
> before it becomes a direct child of the root forever.

So:

* Total pointer changes across **all operations** is very small
* Amortized cost per operation becomes **almost constant**

---

## 9. Amortized Analysis (Important Word)

Key phrase to use:

> **Amortized time complexity**

Meaning:

* Some operations are expensive
* But averaged over all operations â†’ constant

DSU analysis is **amortized**, not per single operation.

---

## 10. Final Formal Result

For **N elements** and **M operations**:

```
Total Time = O(M Â· Î±(N))
```

Since:

```
Î±(N) â‰¤ 4
```

We say:

```
â‰ˆ O(M)
â‰ˆ O(1) per operation
```

---

## 11. Why Interviewers Donâ€™t Expect Full Proof

* Full proof involves **Tarjanâ€™s analysis**
* Heavy recursive mathematics
* Not expected unless PhD-level algorithms

What **is expected**:

* Log N height due to rank
* Tree flattening due to path compression
* Î±(N) grows extremely slowly

---

## 12. One-Line Interview Answer â­

> *â€œUsing union by rank ensures logarithmic height, and path compression flattens the tree aggressively. Together, the amortized complexity becomes O(Î±(N)), where Î±(N) is the inverse Ackermann function, which is â‰¤ 4 for all practical values of N, so operations are effectively constant time.â€*

---
